{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECAP - Bu not defterini Google Colab ile aÃ§Ä±n ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Wine review Kaggle challenge'dan verileri yÃ¼kleyin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV dosyasÄ±nÄ± indirin (Ã¶rneÄŸin Kaggle API kullanarak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArdÄ±ndan, Kaggle hesabÄ±nÄ±za gidin ve â€œYeni API TOKENâ€ oluÅŸturun. BilgisayarÄ±nÄ±za kaydedebileceÄŸiniz bir dosyanÄ±n indirilmesi baÅŸlayacaktÄ±r. Åimdi, bu dosyayÄ± aÅŸaÄŸÄ±daki komutla yÃ¼klemeniz gerekir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu iÅŸlem tamamlandÄ±ktan sonra, ÅŸunu Ã§alÄ±ÅŸtÄ±rÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp \"kaggle.json\" ~/.kaggle/kaggle.json\n",
    "# Give read & write rights\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArtÄ±k veri setini aÅŸaÄŸÄ±daki baÄŸlantÄ±dan indirebilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d zynicide/wine-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArtÄ±k dosyalarÄ± aÃ§abiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('wine-reviews.zip', 'r')\n",
    "zip_ref.extractall('files')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ä°ndirdiÄŸiniz dosyalarÄ± kontrol edelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAM'e yÃ¼kleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = 'files'\n",
    "df = pd.read_csv(os.path.join(data_path, 'winemag-data-130k-v2.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri kÃ¼mesinin her satÄ±rÄ± bir ÅŸarap tanÄ±mÄ±na karÅŸÄ±lÄ±k gelir. Verilerde neler olduÄŸunu, Ã¶zellikle de farklÄ± sÃ¼tunlarÄ± inceleyelim:\n",
    "- ÅŸarap ÅŸiÅŸesinin fiyatÄ±\n",
    "- tanÄ±mÄ±\n",
    "- sahip olduÄŸu â€œpuanâ€ sayÄ±sÄ± (0 ile 100 arasÄ±nda bir Ã¶lÃ§ekte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buradaki amaÃ§ veri mÃ¼hendisliÄŸi yapmak deÄŸildir. Ã–yleyse, ilgili satÄ±rlarÄ± kaldÄ±rarak eksik deÄŸerleri halledelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ÅiÅŸe AÃ§Ä±klamasÄ±ndan Åarap FiyatÄ±nÄ± Tahmin Etme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X,y OluÅŸtur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EÄŸitim setimizi oluÅŸturun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df['description'].values\n",
    "y = df['price'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunu kelimelere ayÄ±ralÄ±m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "X_words = [text_to_word_sequence(sentence) for sentence in X_text]\n",
    "X_words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir sonraki adÄ±m, kelimelerinizi tokenlere dÃ¶nÃ¼ÅŸtÃ¼rmektir, Ã§Ã¼nkÃ¼ bilgisayar bu tokenlerle Ã§alÄ±ÅŸacaktÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_words)\n",
    "X_tokens = tk.texts_to_sequences(X_text)\n",
    "\n",
    "# Vocab size?\n",
    "vocab_size = len(tk.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Åimdi, **verileri doldurmamÄ±z** gerekiyor. Ã–nce `sentence_length` deÄŸerini kontrol edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot([len(x) for x in X_tokens]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length_padding seÃ§in\n",
    "maxlen = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_pad = pad_sequences(X_tokens, dtype=float, padding='post', maxlen=maxlen)\n",
    "X_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her zaman ortalama fiyatÄ± tahmin ederken temel MAE puanÄ±\n",
    "y_mean = y.mean()\n",
    "mae_baseline = np.mean(np.abs(y - y_mean))\n",
    "print(\"MAE Baseline:\", f\"{mae_baseline:.2f}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã–ncelikle bir NLP modeli oluÅŸturalÄ±m. Bu sefer iÅŸlevsel API'yi kullanacaÄŸÄ±z. Sadece eÄŸlence iÃ§in deÄŸil. Nedenini daha sonra gÃ¶receksiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding boyutu?\n",
    "embedding_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Model girdilerini, katmanlarÄ±nÄ± ve Ã§Ä±ktÄ±larÄ±nÄ± tanÄ±mlayÄ±n\n",
    "inputs_nlp = Input(shape=(maxlen,))\n",
    "x = layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_size, mask_zero=True)(inputs_nlp)\n",
    "x = layers.Conv1D(10, kernel_size=15, padding='same', activation=\"relu\")(x)\n",
    "x = layers.Conv1D(10, kernel_size=10, padding='same', activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(30, activation='relu')(x)\n",
    "x = layers.Dropout(0.15)(x)\n",
    "outputs_nlp = layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "# Modeli tanÄ±mlayÄ±n\n",
    "model_nlp = Model(inputs=inputs_nlp, outputs=outputs_nlp)\n",
    "\n",
    "model_nlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard'a hoÅŸ geldiniz ğŸ˜!\n",
    "Bu, Sinir AÄŸÄ±nÄ±n nasÄ±l eÄŸitildiÄŸini gÃ¶rmek iÃ§in harika bir araÃ§tÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard notebook uzantÄ±sÄ±nÄ± yÃ¼kleyin\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Ã–nceki Ã§alÄ±ÅŸmalardan kalan tÃ¼m loglarÄ± temizle\n",
    "!rm -rf ./logs/\n",
    "\n",
    "# loglarÄ± bir klasÃ¶rde saklayacaÄŸÄ±z (her fit iÃ§in bir klasÃ¶r)\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Åimdi, fit'lerimizin gÃ¼nlÃ¼kleri, TensorBoard'un ihtiyaÃ§ duyduÄŸu bazÄ± bilgileri depolayan Ã¶zel olarak tasarlanmÄ±ÅŸ bir klasÃ¶re verilecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=2)\n",
    "\n",
    "model_nlp.compile(loss=\"mse\", optimizer=Adam(learning_rate=1e-4), metrics=['mae'])\n",
    "\n",
    "model_nlp.fit(X_pad, y,\n",
    "          validation_split=0.3,\n",
    "          epochs=50,\n",
    "          batch_size=32,\n",
    "          callbacks=[es, tensorboard_callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SayÄ±sal Ã¶zelliklerden fiyatÄ± tahmin etmek?\n",
    "\n",
    "Ã–rneÄŸin, her ÅŸiÅŸenin puanlarÄ± (0 ila 100 arasÄ±nda bir Ã¶lÃ§ekte), bir ÅŸarabÄ±n ne kadar ucuz veya pahalÄ± olabileceÄŸini bize sÃ¶ylemelidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter('price', 'points')\n",
    "plt.xlim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaÅŸka hangi kategorik deÄŸiÅŸkenleri One Hot Encoding ile kodlayabiliriz?\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "X_region_ohe = ohe.fit_transform(df[['region_2']]) # Buraya diÄŸer sÃ¼tunlarÄ± ekleyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price ve OHE sÃ¼tunlarÄ±nÄ± birleÅŸtirin\n",
    "X_num = np.hstack([df[['points']].values, X_region_ohe])\n",
    "pd.DataFrame(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her ÅŸeyi Ã¶lÃ§eklendirin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_num = StandardScaler().fit_transform(X_num)\n",
    "print(X_num.shape)\n",
    "pd.DataFrame(X_num).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model girdilerini, katmanlarÄ±nÄ± ve Ã§Ä±ktÄ±larÄ±nÄ± tanÄ±mlayÄ±n\n",
    "inputs_num = Input(shape=(X_num.shape[1],))\n",
    "x = layers.Dense(64, activation=\"relu\")(inputs_num)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs_num = layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "# Modeli tanÄ±mlayÄ±n\n",
    "model_num = Model(inputs=inputs_num, outputs=outputs_num)\n",
    "\n",
    "model_num.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=2)\n",
    "\n",
    "model_num.compile(loss = \"mse\", optimizer=Adam(learning_rate=5e-4), metrics=['mae'])\n",
    "model_num.fit(X_num, y,\n",
    "          validation_split=0.3,\n",
    "          epochs=50,\n",
    "          batch_size=32,\n",
    "          callbacks=[es]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. BirleÅŸtirilmiÅŸ RNN + Tablo verileri GiriÅŸleri !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN ve Tabular veri modelini birleÅŸtiren bir model oluÅŸturalÄ±m.\n",
    "\n",
    "Bu nedenle daha Ã¶nce iÅŸlevsel API'yi kullandÄ±k: daha geliÅŸmiÅŸ model yapÄ±larÄ± oluÅŸturmamÄ±zÄ± saÄŸlÄ±yor. Bu birleÅŸtirilmiÅŸ model artÄ±k SÄ±ralÄ± bir model deÄŸil!\n",
    "\n",
    "Ä°ki modeli oluÅŸtururken, hem giriÅŸleri hem de Ã§Ä±kÄ±ÅŸlarÄ± oluÅŸturduk. ArtÄ±k bunlarÄ± birleÅŸtirebilir ve Ã¼stlerine kÃ¼Ã§Ã¼k bir Dense network ekleyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Girdileri birleÅŸtirin\n",
    "inputs = [inputs_nlp, inputs_num]\n",
    "\n",
    "# Ã‡Ä±ktÄ±larÄ± birleÅŸtirin\n",
    "combined = layers.concatenate([outputs_nlp, outputs_num])\n",
    "\n",
    "# Ä°ki Dense katmanÄ± ekle\n",
    "x = layers.Dense(10, activation=\"relu\")(combined)\n",
    "outputs = layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# Ve modeli oluÅŸturun\n",
    "model_combined = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined.summary() #ğŸ¤®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ˜ Daha iyi Ã¶zet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.plot_model(model_combined, \"multi_input_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Åimdi, bunlarÄ± birleÅŸtirip uyarlayabiliriz!\n",
    "\n",
    "`X` verilerine dikkat edin: hem metin hem de sayÄ±sal girdileri iÃ§ermelidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined.compile(loss=\"mse\", optimizer=Adam(learning_rate=1e-4), metrics=['mae'])\n",
    "es = EarlyStopping(patience=2)\n",
    "\n",
    "model_combined.fit(x=[X_pad, X_num],\n",
    "                   y=y,\n",
    "                   validation_split=0.3,\n",
    "                   epochs=100,\n",
    "                   batch_size=32,\n",
    "                   callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EÄŸitim sÃ¼rerken neler olduÄŸuna bir bakalÄ±m. EÄŸitimin oldukÃ§a iyi bir MAE ile baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yor musunuz?**\n",
    "\n",
    "Ã‡Ä±ktÄ±larÄ± yeniden baÅŸlatmadÄ±k: Ã¶ncekileri yeniden kullandÄ±k ve bunlar ayrÄ± modellerde zaten eÄŸitilmiÅŸti. YalnÄ±zca derleme ve uyumlama yaptÄ±ÄŸÄ±mÄ±z iÃ§in, eÄŸitim iki alt modelden zaten Ã¶ÄŸrenilmiÅŸ olan aÄŸÄ±rlÄ±klardan baÅŸlÄ±yor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her akÄ±ÅŸ/dal, bir veri giriÅŸ kaynaÄŸÄ± olarak dÃ¼ÅŸÃ¼nÃ¼lebilir. Bu tÃ¼r verilerle karÅŸÄ±laÅŸabileceÄŸiniz birÃ§ok kullanÄ±m Ã¶rneÄŸi var mÄ±?\n",
    "\n",
    "# 5. Bu tÃ¼r verilere sahip olabileceÄŸiniz herhangi bir Ã¶rnek var mÄ±?\n",
    "\n",
    "- TÄ±bbi veriler: EKG, EEG, MRI, PET, biliÅŸsel deÄŸerlendirmeler, biyobelirteÃ§ler, ...\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/medical_data.png\" width='70%'>\n",
    "\n",
    "- Nesne algÄ±lama, Ã¶rneÄŸin otonom araÃ§larda birÃ§ok sensÃ¶re (birden fazla kamera, radar, hÄ±z, harita vb.) dayalÄ± olarak karar verdiÄŸiniz durumlarda.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/autonomous_vehicle.png\" width='70%'>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
